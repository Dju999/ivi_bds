{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ivi Big Data school\n",
    "\n",
    "## pyspark\n",
    "\n",
    "### Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate() # гвоздь программы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+-------------+\n",
      "|   user_id|       operator_name|content_id|show_duration|\n",
      "+----------+--------------------+----------+-------------+\n",
      "| 827375963|          Rostelecom|      9966|         1400|\n",
      "| 890810589|          LLC TOMTEL|     10140|         1271|\n",
      "| 929088258|OJS Moscow city t...|      9572|           30|\n",
      "| 987577016|          Rostelecom|      8014|         1310|\n",
      "| 573841374|OJS Moscow city t...|      9983|         3205|\n",
      "| 757852413|Ekaterinburg-2000...|      9572|         3105|\n",
      "| 991611208|RECONN. Operator ...|      9983|         2998|\n",
      "| 914647005|          Rostelecom|      7097|         2870|\n",
      "| 924157490|Multiservice Netw...|     10073|         2569|\n",
      "|1005188286|   Prime-Service LLC|      9572|         3095|\n",
      "| 956265133|OJS Moscow city t...|     10427|         3085|\n",
      "| 736604024|     E-Light-Telecom|      9572|         3095|\n",
      "| 852100063|     E-Light-Telecom|      9983|         3111|\n",
      "| 966231004|Closed Joint Stoc...|      9195|            5|\n",
      "|1009409756|          Rostelecom|      9572|         3141|\n",
      "| 617823607|     Novotelecom Ltd|      9786|         1333|\n",
      "| 785668819|  Teleseti Plus Ltd.|      7097|         1165|\n",
      "| 939987562|           OJSC RITC|      9572|           40|\n",
      "| 986453029|PE Tsibrankov Kon...|      7097|          632|\n",
      "|1007882880|     E-Light-Telecom|     10208|          240|\n",
      "+----------+--------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# читаем из подготовленного CSV\n",
    "# cache - означает, что данные будут не только считаны с диска, но и подгружены память\n",
    "# по умолчанию, без кэширования, Spark работает так же, как и MapReduce - читает с диска и пишет на диск\n",
    "df = spark.read.csv(\"content_watch.csv\", inferSchema=True, header=True, nullValue=\"None\").cache()\n",
    "# смотрим, что получилось\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый взгляд на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "только имена колонок:\n",
      "['user_id', 'operator_name', 'content_id', 'show_duration']\n",
      "\n",
      "имена колонок с типами данных:\n",
      "[('user_id', 'int'), ('operator_name', 'string'), ('content_id', 'int'), ('show_duration', 'int')]\n",
      "\n",
      "полное описание типа данных строки в DataFrame в синтаксисе pyspark.sql.types:\n",
      "StructType(List(StructField(user_id,IntegerType,true),StructField(operator_name,StringType,true),StructField(content_id,IntegerType,true),StructField(show_duration,IntegerType,true)))\n",
      "\n",
      "простейшая статистика:\n",
      "+-------+--------------------+--------------------+------------------+------------------+\n",
      "|summary|             user_id|       operator_name|        content_id|     show_duration|\n",
      "+-------+--------------------+--------------------+------------------+------------------+\n",
      "|  count|               20000|               20000|             20000|             17928|\n",
      "|   mean|   8.6525109116155E8|                null|        17391.6428|1272.5749665327978|\n",
      "| stddev|1.6811632041240516E8|                null|32636.639667408333|1294.6419975352087|\n",
      "|    min|               46429|21 Century Teleco...|               949|                 0|\n",
      "|    max|          1010558449|     umos Center LLC|            191504|             10184|\n",
      "+-------+--------------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"только имена колонок:\")\n",
    "print(df.columns)\n",
    "print(\"\\nимена колонок с типами данных:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nполное описание типа данных строки в DataFrame в синтаксисе pyspark.sql.types:\")\n",
    "print(df.schema)\n",
    "# метод describe возвращает DataFrame, а не просто печатает табличку\n",
    "# поэтому мы ещё вызываем метод show, который просто печатает\n",
    "print(\"\\nпростейшая статистика:\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Обратите внимание, что:\n",
    "* Spark обычно правильно определяет тип колонок в CSV (но это требует двойного прохода по данным во время чтения)\n",
    "* чтобы избежать двойного чтения CSV, можно передать схему данных в метод csv\n",
    "* у строк в DataFrame, вообще говоря, нет порядка - в production они хранятся распределённо на нескольких серверах\n",
    "* поэтому сортировать строки в самом DataFrame _невозможно_\n",
    "* но можно сортировать результаты различных операций с DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Доступ к данным\n",
    "\n",
    "как брать различные срезы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|  user_id|content_id|\n",
      "+---------+----------+\n",
      "|827375963|      9966|\n",
      "|890810589|     10140|\n",
      "|929088258|      9572|\n",
      "+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Срез по колонкам \n",
    "col_slice = [\"user_id\", \"content_id\"]\n",
    "# можно просить показать разное количество строк\n",
    "df[col_slice].show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Обратите внимание:\n",
    "* в Spark строки DataFrame, вообще говоря, не хранятся в памяти одной машины в определённом порядке\n",
    "* поэтому никаких loc/iloc, аналогичных pandas, в Spark нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "было\n",
      "user_id 0\n",
      "operator_name 0\n",
      "content_id 0\n",
      "show_duration 2072\n",
      "\n",
      "стало\n",
      "user_id 0\n",
      "operator_name 0\n",
      "content_id 0\n",
      "show_duration 0\n"
     ]
    }
   ],
   "source": [
    "# сколько пустых значений в разных колонках\n",
    "from pyspark.sql.functions import isnull\n",
    "\n",
    "def print_null_stat(df):\n",
    "    for column_name in df.columns:\n",
    "        print(column_name, df.where(isnull(column_name)).count())\n",
    "\n",
    "# заполним пустые значения нулями\n",
    "print(\"было\")\n",
    "print_null_stat(df)\n",
    "df = df.fillna(0)\n",
    "print(\"\\nстало\")\n",
    "print_null_stat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+----------+-------------+\n",
      "|  user_id|operator_name|content_id|show_duration|\n",
      "+---------+-------------+----------+-------------+\n",
      "|603396239| Beeline Home|      7029|           65|\n",
      "|985861659|   Skynet Ltd|      7029|           19|\n",
      "|958739701|    VimpelCom|      7029|           11|\n",
      "+---------+-------------+----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+\n",
      "|content_id|\n",
      "+----------+\n",
      "|      7029|\n",
      "|      7029|\n",
      "|      7029|\n",
      "+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# другие способ получить логический срез\n",
    "df[col(\"content_id\") == 7029].show(3)\n",
    "df[col(\"content_id\") == 7029][[\"content_id\"]].show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-------------+\n",
      "|   user_id|operator_name|content_id|show_duration|\n",
      "+----------+-------------+----------+-------------+\n",
      "| 603396239| Beeline Home|      7029|           65|\n",
      "| 788312739| Beeline Home|      7029|            0|\n",
      "|1008874267| Beeline Home|      7029|          126|\n",
      "+----------+-------------+----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+-------------+----------+-------------+\n",
      "|   user_id|operator_name|content_id|show_duration|\n",
      "+----------+-------------+----------+-------------+\n",
      "| 603396239| Beeline Home|      7029|           65|\n",
      "| 788312739| Beeline Home|      7029|            0|\n",
      "|1008874267| Beeline Home|      7029|          126|\n",
      "+----------+-------------+----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# можно строить срезы по нескольким условиям\n",
    "# в виде строки\n",
    "df.where(\"operator_name == 'Beeline Home' and content_id == '7029'\").show(3)\n",
    "# или последовательно применяя фильтры\n",
    "# использовать функцию col необязательно - Spark поддерживает много разных синтаксисов\n",
    "df.where(df.operator_name == 'Beeline Home')\\\n",
    "    .where(df.content_id == '7029').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(show_duration)|\n",
      "+------------------+\n",
      "|         1140.7362|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|avg(show_duration)|\n",
      "+------------------+\n",
      "|1124.2944693572497|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# Агрегаты можно вычислять по столбцам\n",
    "df.agg(mean('show_duration')).show()\n",
    "# можно добавить фильтрацию\n",
    "df[df[\"operator_name\"]==\"Beeline Home\"].agg(mean('show_duration')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+\n",
      "|   user_id|avg(show_duration)|max(show_duration)|min(show_duration)|\n",
      "+----------+------------------+------------------+------------------+\n",
      "|1007882880|             240.0|               240|               240|\n",
      "| 643879096|            3185.0|              3185|              3185|\n",
      "| 897823457|3101.6666666666665|              3150|              3070|\n",
      "+----------+------------------+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min\n",
    "\n",
    "# продвинутая агрегация\n",
    "df.groupby(\"user_id\").agg(mean(\"show_duration\"), max(\"show_duration\"), min(\"show_duration\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-style: джойны\n",
    "\n",
    "в Spark можно объединять разные DataFrame друг с другом в SQL-подобном стиле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|content_id|       content_title|\n",
      "+----------+--------------------+\n",
      "|      9966|                Луна|\n",
      "|     10140|             Солдаты|\n",
      "|      9572|               Мажор|\n",
      "|      8014|Клуб Винкс – Школ...|\n",
      "|      9983|               Метод|\n",
      "|      7097|      Закрытая школа|\n",
      "|     10073|             Косатка|\n",
      "|     10427|Петровка, 38. Ком...|\n",
      "|      9195|Смерть шпионам: С...|\n",
      "|      9786|        Женская доля|\n",
      "|     10208|Даша-путешественница|\n",
      "|     10590|            Чичилэнд|\n",
      "|      9797|Новые приключения...|\n",
      "|     10596|         Добрый Комо|\n",
      "|     10956|             Подмена|\n",
      "|     10275|            Три кота|\n",
      "|      7384|На безымянной высоте|\n",
      "|     10939|          Район тьмы|\n",
      "|      7423|       Неудача Пуаро|\n",
      "|      6793|     Битва за Москву|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# подготовим данные для join\n",
    "content_watch = df\n",
    "content = spark.read.csv(\"content_title.csv\", inferSchema=True, header=True, nullValue=\"None\").cache()\n",
    "content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+-------------+--------------------+\n",
      "|content_id|   user_id|       operator_name|show_duration|       content_title|\n",
      "+----------+----------+--------------------+-------------+--------------------+\n",
      "|      9966| 827375963|          Rostelecom|         1400|                Луна|\n",
      "|     10140| 890810589|          LLC TOMTEL|         1271|             Солдаты|\n",
      "|      9572| 929088258|OJS Moscow city t...|           30|               Мажор|\n",
      "|      8014| 987577016|          Rostelecom|         1310|Клуб Винкс – Школ...|\n",
      "|      9983| 573841374|OJS Moscow city t...|         3205|               Метод|\n",
      "|      9572| 757852413|Ekaterinburg-2000...|         3105|               Мажор|\n",
      "|      9983| 991611208|RECONN. Operator ...|         2998|               Метод|\n",
      "|      7097| 914647005|          Rostelecom|         2870|      Закрытая школа|\n",
      "|     10073| 924157490|Multiservice Netw...|         2569|             Косатка|\n",
      "|      9572|1005188286|   Prime-Service LLC|         3095|               Мажор|\n",
      "|     10427| 956265133|OJS Moscow city t...|         3085|Петровка, 38. Ком...|\n",
      "|      9572| 736604024|     E-Light-Telecom|         3095|               Мажор|\n",
      "|      9983| 852100063|     E-Light-Telecom|         3111|               Метод|\n",
      "|      9195| 966231004|Closed Joint Stoc...|            5|Смерть шпионам: С...|\n",
      "|      9572|1009409756|          Rostelecom|         3141|               Мажор|\n",
      "|      9786| 617823607|     Novotelecom Ltd|         1333|        Женская доля|\n",
      "|      7097| 785668819|  Teleseti Plus Ltd.|         1165|      Закрытая школа|\n",
      "|      9572| 939987562|           OJSC RITC|           40|               Мажор|\n",
      "|      7097| 986453029|PE Tsibrankov Kon...|          632|      Закрытая школа|\n",
      "|     10208|1007882880|     E-Light-Telecom|          240|Даша-путешественница|\n",
      "+----------+----------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_watch.join(content, how=\"left\", on=\"content_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "## Разминочная часть"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Какой фильм был просмотрен максимальным количеством человек?\n",
    "Какой пользователь посмотрел больше всех фильмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У какого оператора больше всего пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой средний показатель по числу просмотренных фильмов среди мужчин - пользователе Ростелекома?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить по данным файла content_watch.csv матрицу user-item\n",
    "\n",
    "В матрице должно быть 3 столбца\n",
    "\n",
    "Первый столбец - user_id\n",
    "\n",
    "Второй столбец - list из content_id, которые смотрел user_id. Оставлять нужно только уникальные id контента - повторов быть не должно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
